## Weed-Sentiment-Analysis-NLP
3.1.3. Twitter Data Collection (Wang)

To retrieve relevant Twitter data for this research, we customized a web scraping script developed using Python. The first thing we need to do is to establish a search endpoint: the script targets the GraphQL endpoint of Twitter for search queries. GraphQL is a query language that allows precise fetching of required data. To initialize, we created the `Gtwitter` class, once instantiated, is set with a `max_page` parameter, defining the maximum number of pages to scrape. This prevents over-scraping and limits the volume of data retrieved. The `getblog` function within the class handles the communication with Twitter's server. It prepares a request with necessary headers, which include authorization, user-agent, and other pertinent information. At the same time randomized cookies are chosen to simulate different user sessions. Error handling is also incorporated to manage rate limits imposed by Twitter. When faced with a rate limit, the script would pause and retry. To parse the data, the retrieved data is processed using the `parse` function. This function navigates through the JSON response to extract individual tweet details. Details such as tweet creation date, username, tweet content, retweet count, favorite count, and several others are extracted. The script particularly focuses on tweets with the keyword 'California' and its associated city saves those details into a temporary file for subsequent processing. Only tweets containing keywords ‘Weed’ are considered to ensure relevance to the study. Relevant tweet details are stored in a temporary file named "tepm.txt". Each tweet's details are stored as a JSON object on a new line. The script incorporates a utility function `generXlsx` that reads the saved tweet details and converts them into an Excel file format using the pandas library. This ensures easy readability and further data analysis using traditional data analysis tools. The `changev` function is used for transforming Twitter's timestamp into a standardized date-time format. The `blockdata` function orchestrates the overall flow of data retrieval and parsing. It handles pagination by analyzing the response to determine the cursor for the next page of tweets. The `getdaterange` function is a utility function to get a list of dates between a start and end date. 

